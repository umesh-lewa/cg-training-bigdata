
http://hadoop.apache.org/

http://spark.apache.org/

https://www.scala-lang.org/download/2.11.12.html
https://www.scala-lang.org/download/2.12.8.html

https://demo.gethue.com/hue/filebrowser/view=s3a%3A%2F%2Fdemo-gethue

http://hive.apache.org/

https://www.tutorialspoint.com/hive/hive_create_table.htm

https://atomicobject.com/resources/oo-programming/naming-conventions
https://pspdfkit.com/blog/2018/naming-classes-why-it-matters-how-to-do-it-well/
https://www.tiobe.com/tiobe-index/
https://pypl.github.io/PYPL.html
https://www.meetup.com/topics/silicon-valley/

https://www.tutorialspoint.com/hive/hiveql_joins.htm

https://tez.apache.org/

https://www.rabbitmq.com/
https://activemq.apache.org/
https://zeromq.org/
https://en.wikipedia.org/wiki/Enterprise_messaging_system
https://aws.amazon.com/pub-sub-messaging/
https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern

https://kafka.apache.org/downloads

./hdfs namenode -format

ps -ef | grep hadoop
$ top
quit - q
12 digit random number
11 - blum blum shub
12 - digit - verhoeff
http://www.augustana.ualberta.ca/~mohrj/algorithms/checkdigit.html

$ ssh-keygen -t rsa -P ‘’ -f ~/.ssh/id_rsa
$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
$ chmod 0600 ~/.ssh/authorized_keys

export HDFS_NAMENODE_USER="root"
export HDFS_DATANODE_USER="root"
export HDFS_SECONDARYNAMENODE_USER="root"
export YARN_RESOURCEMANAGER_USER="root"
export YARN_NODEMANAGER_USER="root"

HDFS_DATANODE_USER=root
HADOOP_SECURE_DN_USER=hdfs 
HDFS_NAMENODE_USER=root 
HDFS_SECONDARYNAMENODE_USER=root 

// local
// local[*]
// Yarn - yet another resource negotiator
// EMR
// mesos
// spark
// kubernetes

http://mesos.apache.org/
https://kubernetes.io/


CREATE TABLE um_test_db.um_test_tb(id INT,col1 STRING,col2 STRING)

export HDFS_NAMENODE_USER="root"
export HDFS_DATANODE_USER="root"
export HDFS_SECONDARYNAMENODE_USER="root"
export YARN_RESOURCEMANAGER_USER="root"
export YARN_NODEMANAGER_USER="root"

Chin Feynman  3:37 PM
HDFS_DATANODE_USER=root
HADOOP_SECURE_DN_USER=hdfs 
HDFS_NAMENODE_USER=root 
HDFS_SECONDARYNAMENODE_USER=root 

parquet, avro and orc

https://github.com/achinnasamy?tab=repositories
https://github.com/achinnasamy/wernerkafka
https://github.com/achinnasamy/sparktraining/blob/master/src/main/java/com/dmac/analytics/spark/SparkRunningInWindows.java
https://github.com/achinnasamy/sparktraining/tree/master/config

https://en.wikipedia.org/wiki/CAP_theorem#:~:text=In%20theoretical%20computer%20science%2C%20the,recent%20write%20or%20an%20error

https://github.com/Wignesh/bd-env

docker run -p 8080:8080 -p 8081:8081 -p 9870:9870 -p 9864:9864 -p 9866:9866 -p 9867:9867 -p 9868:9868 -p 9000:9000 bd-env

COPY /data/CountSparkJob.jar /usr/bin/bd/testData/
COPY /data/auth.csv /usr/bin/bd/testData/

docker build -t bd-env .
docker run -v ${PWD}:/usr/bin/bd/fs -p 8080:8080 -p 8081:8081 -p 9870:9870 -p 9864:9864 -p 9866:9866 -p 9867:9867 -p 9868:9868 -p 9000:9000 bd-env

./spark-submit --name CodaDataJOB --master spark://eb0988bbd19c:7077 --deploy-mode client --class com.presidio.spark.SparkRunner /usr/bin/bd/ScalaTest8-1.0-SNAPSHOT.jar

./spark-submit --name AccumulatorJOB --master spark://Umeshs-MacBook-Pro.local:7077 --deploy-mode client --class com.presidio.spark.ClientMain /Users/umeshmoorthy/code/gitStuff/myStuff/cg-training-bigdata/Day_11/ScalaTest11_2/target/ScalaTest11-1.0-SNAPSHOT.jar


Create New Topic
./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 4 --topic MONGODB-TOPIC

Read log file from partition
./kafka-run-class.sh kafka.tools.DumpLogSegments --deep-iteration --print-data-log --files /tmp/kafka-logs/MONGODB-TOPIC-0/00000000000000000000.log
Dumping /tmp/kafka-logs/MONGODB-TOPIC-0/00000000000000000000.log

 

https://timepasstechies.com/scala-interpreter-design-pattern-example-scala/
https://timepasstechies.com/scala-mediator-design-pattern-real-world-example-scala/
https://timepasstechies.com/scala-custom-iterator-example/